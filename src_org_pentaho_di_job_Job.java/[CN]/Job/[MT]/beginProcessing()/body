{
  currentDate=new Date();
  logDate=new Date();
  startDate=Const.MIN_DATE;
  endDate=currentDate;
  resetErrors();
  final JobLogTable jobLogTable=jobMeta.getJobLogTable();
  int intervalInSeconds=Const.toInt(environmentSubstitute(jobLogTable.getLogInterval()),-1);
  if (jobLogTable.isDefined()) {
    DatabaseMeta logcon=jobMeta.getJobLogTable().getDatabaseMeta();
    String schemaName=environmentSubstitute(jobMeta.getJobLogTable().getActualSchemaName());
    String tableName=environmentSubstitute(jobMeta.getJobLogTable().getActualTableName());
    String schemaAndTable=jobMeta.getJobLogTable().getDatabaseMeta().getQuotedSchemaTableCombination(schemaName,tableName);
    Database ldb=new Database(this,logcon);
    ldb.shareVariablesWith(this);
    ldb.connect();
    ldb.setCommit(logCommitSize);
    try {
      Long id_batch=new Long(1);
      if (jobMeta.getJobLogTable().isBatchIdUsed()) {
        id_batch=logcon.getNextBatchId(ldb,schemaName,tableName,jobLogTable.getKeyField().getFieldName());
        setBatchId(id_batch.longValue());
        if (getPassedBatchId() <= 0) {
          setPassedBatchId(id_batch.longValue());
        }
      }
      Object[] lastr=ldb.getLastLogDate(schemaAndTable,jobMeta.getName(),true,LogStatus.END);
      if (!Const.isEmpty(lastr)) {
        Date last;
        try {
          last=ldb.getReturnRowMeta().getDate(lastr,0);
        }
 catch (        KettleValueException e) {
          throw new KettleJobException(BaseMessages.getString(PKG,"Job.Log.ConversionError","" + tableName),e);
        }
        if (last != null) {
          startDate=last;
        }
      }
      depDate=currentDate;
      ldb.writeLogRecord(jobMeta.getJobLogTable(),LogStatus.START,this,null);
      if (!ldb.isAutoCommit())       ldb.commit(true);
      ldb.disconnect();
      if (intervalInSeconds > 0) {
        final Timer timer=new Timer(getName() + " - interval logging timer");
        TimerTask timerTask=new TimerTask(){
          public void run(){
            try {
              endProcessing();
            }
 catch (            Exception e) {
              log.logError(BaseMessages.getString(PKG,"Job.Exception.UnableToPerformIntervalLogging"),e);
              errors.incrementAndGet();
              stopAll();
            }
          }
        }
;
        timer.schedule(timerTask,intervalInSeconds * 1000,intervalInSeconds * 1000);
        addJobListener(new JobAdapter(){
          public void jobFinished(          Job job){
            timer.cancel();
          }
        }
);
      }
      addJobListener(new JobAdapter(){
        public void jobFinished(        Job job){
          try {
            endProcessing();
          }
 catch (          Exception e) {
            log.logError(BaseMessages.getString(PKG,"Job.Exception.UnableToWriteToLoggingTable",jobLogTable.toString()),e);
          }
        }
      }
);
    }
 catch (    KettleDatabaseException dbe) {
      addErrors(1);
      throw new KettleJobException(BaseMessages.getString(PKG,"Job.Log.UnableToProcessLoggingStart","" + tableName),dbe);
    }
 finally {
      ldb.disconnect();
    }
  }
  JobEntryLogTable jobEntryLogTable=jobMeta.getJobEntryLogTable();
  if (jobEntryLogTable.isDefined()) {
    addJobListener(new JobAdapter(){
      public void jobFinished(      Job job) throws KettleException {
        try {
          writeJobEntryLogInformation();
        }
 catch (        KettleException e) {
          throw new KettleException(BaseMessages.getString(PKG,"Job.Exception.UnableToPerformJobEntryLoggingAtJobEnd"),e);
        }
      }
    }
);
  }
  ChannelLogTable channelLogTable=jobMeta.getChannelLogTable();
  if (channelLogTable.isDefined()) {
    addJobListener(new JobAdapter(){
      public void jobFinished(      Job job) throws KettleException {
        try {
          writeLogChannelInformation();
        }
 catch (        KettleException e) {
          throw new KettleException(BaseMessages.getString(PKG,"Trans.Exception.UnableToPerformLoggingAtTransEnd"),e);
        }
      }
    }
);
  }
  return true;
}
