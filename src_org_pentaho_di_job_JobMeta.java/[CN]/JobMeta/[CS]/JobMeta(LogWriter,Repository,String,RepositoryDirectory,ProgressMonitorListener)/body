{
  this.log=log;
synchronized (rep) {
    try {
      clear();
      directory=repdir;
      setID(rep.getJobID(jobname,repdir.getID()));
      if (getID() > 0) {
        long noteids[]=rep.getJobNoteIDs(getID());
        long jecids[]=rep.getJobEntryCopyIDs(getID());
        long hopid[]=rep.getJobHopIDs(getID());
        int nrWork=2 + noteids.length + jecids.length+ hopid.length;
        if (monitor != null)         monitor.beginTask(BaseMessages.getString(PKG,"JobMeta.Monitor.LoadingJob") + repdir + Const.FILE_SEPARATOR+ jobname,nrWork);
        if (monitor != null)         monitor.subTask(BaseMessages.getString(PKG,"JobMeta.Monitor.ReadingJobInformation"));
        RowMetaAndData jobRow=rep.getJob(getID());
        setName(jobRow.getString(Repository.FIELD_JOB_NAME,null));
        description=jobRow.getString(Repository.FIELD_JOB_DESCRIPTION,null);
        extendedDescription=jobRow.getString(Repository.FIELD_JOB_EXTENDED_DESCRIPTION,null);
        jobVersion=jobRow.getString(Repository.FIELD_JOB_JOB_VERSION,null);
        jobStatus=Const.toInt(jobRow.getString(Repository.FIELD_JOB_JOB_STATUS,null),-1);
        logTable=jobRow.getString(Repository.FIELD_JOB_TABLE_NAME_LOG,null);
        created_user=jobRow.getString(Repository.FIELD_JOB_CREATED_USER,null);
        created_date=jobRow.getDate(Repository.FIELD_JOB_CREATED_DATE,new Date());
        modifiedUser=jobRow.getString(Repository.FIELD_JOB_MODIFIED_USER,null);
        modifiedDate=jobRow.getDate(Repository.FIELD_JOB_MODIFIED_DATE,new Date());
        long id_logdb=jobRow.getInteger(Repository.FIELD_JOB_ID_DATABASE_LOG,0);
        if (id_logdb > 0) {
          logConnection=rep.loadDatabaseMeta(id_logdb);
          logConnection.shareVariablesWith(this);
        }
        useBatchId=jobRow.getBoolean(Repository.FIELD_JOB_USE_BATCH_ID,false);
        batchIdPassed=jobRow.getBoolean(Repository.FIELD_JOB_PASS_BATCH_ID,false);
        logfieldUsed=jobRow.getBoolean(Repository.FIELD_JOB_USE_LOGFIELD,false);
        logSizeLimit=rep.getJobAttributeString(getID(),0,Repository.JOB_ATTRIBUTE_LOG_SIZE_LIMIT);
        if (monitor != null)         monitor.worked(1);
        if (monitor != null)         monitor.subTask(BaseMessages.getString(PKG,"JobMeta.Monitor.ReadingAvailableDatabasesFromRepository"));
        try {
          sharedObjectsFile=jobRow.getString(Repository.FIELD_JOB_SHARED_FILE,null);
          sharedObjects=readSharedObjects(rep);
        }
 catch (        Exception e) {
          LogWriter.getInstance().logError(toString(),BaseMessages.getString(PKG,"JobMeta.ErrorReadingSharedObjects.Message",e.toString()));
          LogWriter.getInstance().logError(toString(),Const.getStackTracker(e));
        }
        if (monitor != null)         monitor.worked(1);
        if (log.isDetailed())         log.logDetailed(toString(),"Loading " + noteids.length + " notes");
        for (int i=0; i < noteids.length; i++) {
          if (monitor != null)           monitor.subTask(BaseMessages.getString(PKG,"JobMeta.Monitor.ReadingNoteNr") + (i + 1) + "/"+ noteids.length);
          NotePadMeta ni=new NotePadMeta(log,rep,noteids[i]);
          if (indexOfNote(ni) < 0)           addNote(ni);
          if (monitor != null)           monitor.worked(1);
        }
        if (log.isDetailed())         log.logDetailed(toString(),"Loading " + jecids.length + " job entries");
        for (int i=0; i < jecids.length; i++) {
          if (monitor != null)           monitor.subTask(BaseMessages.getString(PKG,"JobMeta.Monitor.ReadingJobEntryNr") + (i + 1) + "/"+ (jecids.length));
          JobEntryCopy jec=new JobEntryCopy(log,rep,getID(),jecids[i],jobentries,databases,slaveServers);
          int copyNr=0;
          for (          JobEntryCopy copy : jobcopies) {
            if (jec.getEntry() == copy.getEntry()) {
              copyNr++;
            }
          }
          jec.setNr(copyNr);
          int idx=indexOfJobEntry(jec);
          if (idx < 0) {
            if (jec.getName() != null && jec.getName().length() > 0)             addJobEntry(jec);
          }
 else {
            setJobEntry(idx,jec);
          }
          if (monitor != null)           monitor.worked(1);
        }
        if (log.isDetailed())         log.logDetailed(toString(),"Loading " + hopid.length + " job hops");
        for (int i=0; i < hopid.length; i++) {
          if (monitor != null)           monitor.subTask(BaseMessages.getString(PKG,"JobMeta.Monitor.ReadingJobHopNr") + (i + 1) + "/"+ (jecids.length));
          JobHopMeta hi=new JobHopMeta(rep,hopid[i],this,jobcopies);
          jobhops.add(hi);
          if (monitor != null)           monitor.worked(1);
        }
        loadRepParameters(rep);
        clearChanged();
        if (monitor != null)         monitor.subTask(BaseMessages.getString(PKG,"JobMeta.Monitor.FinishedLoadOfJob"));
        if (monitor != null)         monitor.done();
      }
 else {
        throw new KettleException(BaseMessages.getString(PKG,"JobMeta.Exception.CanNotFindJob") + jobname);
      }
    }
 catch (    KettleException dbe) {
      throw new KettleException(BaseMessages.getString(PKG,"JobMeta.Exception.AnErrorOccuredReadingJob",jobname),dbe);
    }
 finally {
      initializeVariablesFrom(getParentVariableSpace());
      setInternalKettleVariables();
    }
  }
}
