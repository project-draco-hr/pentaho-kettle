{
  try {
    super.loadRep(rep,id_jobentry,databases);
    schemaname=rep.getJobEntryAttributeString(id_jobentry,"schemaname");
    tablename=rep.getJobEntryAttributeString(id_jobentry,"tablename");
    filename=rep.getJobEntryAttributeString(id_jobentry,"filename");
    separator=rep.getJobEntryAttributeString(id_jobentry,"separator");
    enclosed=rep.getJobEntryAttributeString(id_jobentry,"enclosed");
    lineterminated=rep.getJobEntryAttributeString(id_jobentry,"lineterminated");
    limitlines=rep.getJobEntryAttributeString(id_jobentry,"limitlines");
    listcolumn=rep.getJobEntryAttributeString(id_jobentry,"listcolumn");
    highpriority=rep.getJobEntryAttributeBoolean(id_jobentry,"highpriority");
    optionenclosed=rep.getJobEntryAttributeBoolean(id_jobentry,"optionenclosed");
    outdumpvalue=(int)rep.getJobEntryAttributeInteger(id_jobentry,"outdumpvalue");
    iffileexists=(int)rep.getJobEntryAttributeInteger(id_jobentry,"iffileexists");
    addfiletoresult=rep.getJobEntryAttributeBoolean(id_jobentry,"addfiletoresult");
    long id_db=rep.getJobEntryAttributeInteger(id_jobentry,"id_database");
    if (id_db > 0) {
      connection=DatabaseMeta.findDatabase(databases,id_db);
    }
 else {
      connection=DatabaseMeta.findDatabase(databases,rep.getJobEntryAttributeString(id_jobentry,"connection"));
    }
  }
 catch (  KettleDatabaseException dbe) {
    throw new KettleException("Unable to load job entry of type 'table exists' from the repository for id_jobentry=" + id_jobentry,dbe);
  }
}
