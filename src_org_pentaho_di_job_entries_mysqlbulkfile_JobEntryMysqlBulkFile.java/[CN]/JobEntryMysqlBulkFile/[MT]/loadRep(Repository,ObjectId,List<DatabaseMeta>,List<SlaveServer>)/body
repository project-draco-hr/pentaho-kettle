{
  try {
    schemaname=rep.getJobEntryAttributeString(id_jobentry,"schemaname");
    tablename=rep.getJobEntryAttributeString(id_jobentry,"tablename");
    filename=rep.getJobEntryAttributeString(id_jobentry,"filename");
    separator=rep.getJobEntryAttributeString(id_jobentry,"separator");
    enclosed=rep.getJobEntryAttributeString(id_jobentry,"enclosed");
    lineterminated=rep.getJobEntryAttributeString(id_jobentry,"lineterminated");
    limitlines=rep.getJobEntryAttributeString(id_jobentry,"limitlines");
    listcolumn=rep.getJobEntryAttributeString(id_jobentry,"listcolumn");
    highpriority=rep.getJobEntryAttributeBoolean(id_jobentry,"highpriority");
    optionenclosed=rep.getJobEntryAttributeBoolean(id_jobentry,"optionenclosed");
    outdumpvalue=(int)rep.getJobEntryAttributeInteger(id_jobentry,"outdumpvalue");
    iffileexists=(int)rep.getJobEntryAttributeInteger(id_jobentry,"iffileexists");
    addfiletoresult=rep.getJobEntryAttributeBoolean(id_jobentry,"addfiletoresult");
    connection=rep.loadDatabaseMetaFromJobEntryAttribute(id_jobentry,"connection","id_database",databases);
  }
 catch (  KettleDatabaseException dbe) {
    throw new KettleException("Unable to load job entry of type 'table exists' from the repository for id_jobentry=" + id_jobentry,dbe);
  }
}
