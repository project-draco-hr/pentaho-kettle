{
  try {
    super.loadRep(rep,id_jobentry,databases,slaveServers);
    transname=rep.getJobEntryAttributeString(id_jobentry,"name");
    String dirPath=rep.getJobEntryAttributeString(id_jobentry,"dir_path");
    directory=rep.getDirectoryTree().findDirectory(dirPath);
    filename=rep.getJobEntryAttributeString(id_jobentry,"file_name");
    argFromPrevious=rep.getJobEntryAttributeBoolean(id_jobentry,"arg_from_previous");
    execPerRow=rep.getJobEntryAttributeBoolean(id_jobentry,"exec_per_row");
    clearResultRows=rep.getJobEntryAttributeBoolean(id_jobentry,"clear_rows",true);
    clearResultFiles=rep.getJobEntryAttributeBoolean(id_jobentry,"clear_files",true);
    setLogfile=rep.getJobEntryAttributeBoolean(id_jobentry,"set_logfile");
    addDate=rep.getJobEntryAttributeBoolean(id_jobentry,"add_date");
    addTime=rep.getJobEntryAttributeBoolean(id_jobentry,"add_time");
    logfile=rep.getJobEntryAttributeString(id_jobentry,"logfile");
    logext=rep.getJobEntryAttributeString(id_jobentry,"logext");
    loglevel=LogWriter.getLogLevel(rep.getJobEntryAttributeString(id_jobentry,"loglevel"));
    clustering=rep.getJobEntryAttributeBoolean(id_jobentry,"cluster");
    String remoteSlaveServerName=rep.getJobEntryAttributeString(id_jobentry,"slave_server_name");
    remoteSlaveServer=SlaveServer.findSlaveServer(slaveServers,remoteSlaveServerName);
    int argnr=rep.countNrJobEntryAttributes(id_jobentry,"argument");
    arguments=new String[argnr];
    for (int a=0; a < argnr; a++) {
      arguments[a]=rep.getJobEntryAttributeString(id_jobentry,a,"argument");
    }
  }
 catch (  KettleDatabaseException dbe) {
    throw new KettleException("Unable to load job entry of type 'trans' from the repository for id_jobentry=" + id_jobentry,dbe);
  }
}
